#!/bin/bash
# Este script configura e inicia o ambiente Safira AI/ML e automa√ß√£o com Docker Compose.

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Configura√ß√µes do Shell ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
set -Eeuo pipefail
# shopt -s inherit_errexit 2>/dev/null || true
# Trap para exibir uma mensagem de erro e aguardar ao encontrar qualquer erro
trap 'echo -e "\n${RED}‚ùå Erro durante execu√ß√£o. Verifique os logs acima.${RESET}"; read -n 1 -s -r -p "\n${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"' ERR

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Cores ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BOLD="\e[1m"; GREEN="\e[32m"; RED="\e[31m"; YELLOW="\e[33m"; CYAN="\e[36m"; RESET="\e[0m"
echo_info() { echo -e "${CYAN}[INFO]${RESET} $1"; }
echo_done() { echo -e "${GREEN}[OK]${RESET} $1"; }
echo_warn() { echo -e "${YELLOW}[AVISO]${RESET} $1"; }
echo_error() { echo -e "${RED}[ERRO]${RESET} $1"; }

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Vari√°veis ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DOCKER_COMPOSE_FILE="docker-compose.yaml"
ENV_FILE=".env"
ENV_EXAMPLE_FILE=".env.example"
SD_REPO_URL="https://github.com/AbdBarho/stable-diffusion-webui-docker"
SD_CLONE_PATH="./build/auto1111/stable-diffusion-webui-docker"


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Flags Default ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BUILD_FLAG=""
RESET_FLAG=false
STATUS_FLAG=false
NON_INTERACTIVE=false
ONLY=""

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Parsing de Flags de Linha de Comando ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo_info "Analisando argumentos: $@"
for arg in "$@"; do
  case $arg in
    --build) BUILD_FLAG="--build"; echo_info "Flag --build ativo.";;
    --no-build) BUILD_FLAG=""; echo_info "Flag --no-build ativo.";;
    --reset) RESET_FLAG=true; echo_info "Flag --reset ativo.";;
    --status) STATUS_FLAG=true; echo_info "Flag --status ativo.";;
    --non-interactive) NON_INTERACTIVE=true; echo_info "Flag --non-interactive ativo.";;
    *)
      echo_warn "Argumento '$arg' n√£o reconhecido. Ignorando."
      ;;
  esac
done

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Execu√ß√£o Baseada em Flags Especiais ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
if [ "$RESET_FLAG" = true ]; then
  echo_info "Resetando ambiente Safira..."
  docker compose -f $DOCKER_COMPOSE_FILE down --volumes --remove-orphans || echo_warn "Comando 'docker compose down' falhou ou o ambiente j√° estava limpo."
  echo_done "Ambiente limpo."
  exit 0
fi

if [ "$STATUS_FLAG" = true ]; then
  echo_info "Exibindo status dos containers:"
  docker compose -f $DOCKER_COMPOSE_FILE ps
  exit 0
fi

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Validando pr√©-requisitos ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo_info "Verificando depend√™ncias..."
if [ -z "$BASH" ]; then
  echo_error "Este script foi projetado para rodar em Bash."
  echo_error "Execute-o via './run.sh' ap√≥s dar 'chmod +x' ou explicitamente com 'bash ./run.sh'."
  exit 1
fi
command -v docker >/dev/null 2>&1 || { echo_error "Docker n√£o est√° instalado ou n√£o est√° no PATH."; exit 1; }
command -v docker compose >/dev/null 2>&1 || { echo_error "Docker Compose (V2) n√£o encontrado no PATH. Certifique-se de que a integra√ß√£o WSL do Docker Desktop est√° ativa para esta distribui√ß√£o."; exit 1; }
command -v git >/dev/null 2>&1 || { echo_error "Git n√£o est√° instalado ou n√£o est√° no PATH."; exit 1; }
echo_done "Depend√™ncias verificadas."

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Preparando arquivo .env ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo_info "Verificando arquivo $ENV_FILE..."
if [ ! -f "$ENV_FILE" ]; then
  if [ -f "$ENV_EXAMPLE_FILE" ]; then
    echo_warn "$ENV_FILE n√£o encontrado. Criando a partir de $ENV_EXAMPLE_FILE..."
    cp "$ENV_EXAMPLE_FILE" "$ENV_FILE"
    echo_done "$ENV_FILE gerado."
  else
    echo_error "$ENV_FILE e $ENV_EXAMPLE_FILE n√£o encontrados."
    echo_error "Crie um arquivo $ENV_FILE vazio ou com suas configura√ß√µes necess√°rias."
    read -n 1 -s -r -p "${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"
    exit 1
  fi
else
  echo_done "$ENV_FILE j√° existe."
fi

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Preenchendo vari√°veis sens√≠veis no .env (se interativo) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
echo_info "Validando vari√°veis sens√≠veis no $ENV_FILE..."

ensure_secret() {
  local var="$1"
  local default="$2"
  if ! grep -q "^${var}=" "$ENV_FILE"; then
    echo "${var}=${default}" >> "$ENV_FILE"
  fi
  local current_value=$(grep "^${var}=" "$ENV_FILE" | cut -d '=' -f2-)
  if [ -z "$current_value" ] && [ "$NON_INTERACTIVE" = false ]; then
    read -rp "üîê Informe um valor para ${var}: " input
    sed -i "s|^${var}=.*|${var}=${input}|" "$ENV_FILE"
    echo_done "${var} definido."
  elif [ -z "$current_value" ] && [ "$NON_INTERACTIVE" = true ]; then
     echo_warn "${var} est√° vazio no $ENV_FILE. Ignorando (non-interactive ativo)."
  else
    echo_done "${var} j√° definido."
  fi
}

SECRETS_TO_CHECK=(
  N8N_BASIC_AUTH_PASSWORD
  REDIS_PASSWORD
  MINIO_ROOT_PASSWORD
  POSTGRES_PASSWORD
  GRAFANA_ADMIN_PASSWORD
  JENKINS_ADMIN_PASSWORD
  SD_API_KEY
)

for var in "${SECRETS_TO_CHECK[@]}"; do
  ensure_secret "$var" ""
done
echo_done "Valida√ß√£o de vari√°veis sens√≠veis completa."

echo_info "Garantindo estrutura m√≠nima de pastas e arquivos..."

DIRS=(
  ./build/venom
  ./build/sesame
  ./build/whisper
  ./build/coqui
  ./build/jira
  ./build/blip2
  ./build/auto1111
)

for dir in "${DIRS[@]}"; do
  if [ ! -d "$dir" ]; then
    mkdir -p "$dir"
    echo_info "üìÅ Criado: $dir"
  fi
done
echo_done "Estrutura de diret√≥rios verificada/criada."

echo_info "Verificando arquivos base para o servi√ßo Venom..."
VENOM_PATH=./build/venom
cat <<'EOF_VENOM_PKG' > "$VENOM_PATH/package.json"
{
  "name": "safira-whatsapp",
  "version": "1.0.0",
  "main": "main.js",
  "type": "module",
  "dependencies": {
    "venom-bot": "^5.1.0"
  }
}
EOF_VENOM_PKG
echo_info "üì¶ package.json verificado/criado para Venom"

cat <<'EOF_VENOM_MAIN' > "$VENOM_PATH/main.js"
const { create } = require('venom-bot');

create({
  session: 'safira-whatsapp-session',
  headless: true,
  disableWelcome: true,
  logQR: false,
  folderNameToken: './sessions'
}).then((client) => {
  console.log("Venom client started!");

  client.onMessage((message) => {
    console.log('Mensagem recebida:', message.body);
    if (message.body && message.isGroupMsg === false && message.type === 'chat') {
      client.sendText(message.from, 'Ol√°! Aqui √© a Safira ‚ú®\nRecebi sua mensagem: "' + message.body + '"');
    }
  });

  client.onStateChange((state) => {
    console.log('[Venom State] ', state);
    if (state === 'CONFLICT' || state === 'UNPAIRED' || state === 'UNLAUNCHED') {
      console.error('Venom client disconnected or needs re-pairing.');
    }
  });

}).catch((error) => {
  console.error('Erro ao iniciar Venom client: ', error);
});
EOF_VENOM_MAIN
chmod +x "$VENOM_PATH/main.js"
echo_info "üîß main.js verificado/criado para Venom"

cat <<'EOF_VENOM_DOCKERFILE' > "$VENOM_PATH/Dockerfile"
FROM node:18-alpine
WORKDIR /app
COPY package.json package-lock.json* ./
RUN npm install --production --silent --no-progress
COPY . .
EXPOSE 3000
CMD ["node", "main.js"]
EOF_VENOM_DOCKERFILE
echo_info "üì¶ Dockerfile verificado/criado para Venom"

echo_info "Verificando arquivos base para o servi√ßo Coqui..."
COQUI_PATH=./build/coqui
cat <<'EOF_COQUI_MAIN' > "$COQUI_PATH/main.py"
from TTS.api import TTS
from flask import Flask, request, send_file, jsonify
import uuid
import os
import torch

app = Flask(__name__)

MODEL_NAME = os.getenv("COQUI_MODEL", "tts_models/en/ljspeech/tacotron2-DDC")
DEVICE = os.getenv("COQUI_DEVICE", "cpu")
if DEVICE == "cuda" and not torch.cuda.is_available():
    print("CUDA n√£o dispon√≠vel, for√ßando DEVICE='cpu'")
    DEVICE = "cpu"
elif DEVICE == "cuda":
    print(f"CUDA dispon√≠vel. Usando DEVICE='{DEVICE}'")
else:
    print(f"Usando DEVICE='{DEVICE}'")

try:
    tts = TTS(model_name=MODEL_NAME, progress_bar=False, gpu=(DEVICE == "cuda"))
    print(f"Modelo TTS '{MODEL_NAME}' carregado com sucesso em '{DEVICE}'.")
except Exception as e:
    print(f"Erro ao carregar modelo TTS '{MODEL_NAME}': {e}")
    print("Verifique se o modelo existe, se as depend√™ncias est√£o corretas e se o DEVICE est√° configurado adequadamente.")
    tts = None

@app.route("/speak", methods=["POST"])
def speak():
    if tts is None:
        return jsonify({"error": "Servi√ßo TTS n√£o inicializado"}), 500

    data = request.json
    text = data.get("text", "")
    speaker = data.get("speaker", None)
    language = data.get("language", None)

    if not text:
        return jsonify({"error": "Nenhum texto fornecido"}), 400

    output_path = f"/tmp/{uuid.uuid4()}.wav"
    try:
        tts.tts_to_file(text=text, file_path=output_path, speaker=speaker, language=language)

        if os.path.exists(output_path):
            response = send_file(output_path, mimetype="audio/wav")
            os.remove(output_path)
            return response
        else:
            return jsonify({"error": "Falha ao gerar arquivo de √°udio."}), 500
    except Exception as e:
        print(f"Erro durante a gera√ß√£o do √°udio: {e}")
        return jsonify({"error": f"Erro durante a gera√ß√£o do audio: {e}"}), 500

@app.route("/")
def status():
    if tts is None:
        return jsonify({"status": "error", "message": "Servi√ßo TTS n√£o inicializado."}), 500
    return jsonify({"status": "ok", "model": MODEL_NAME, "device": DEVICE})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=9001)
EOF_COQUI_MAIN
chmod +x "$COQUI_PATH/main.py"
echo_info "üîß main.py verificado/criado para Coqui"

cat <<'EOF_COQUI_DOCKERFILE' > "$COQUI_PATH/Dockerfile"
FROM python:3.10-slim

RUN apt-get update && apt-get install -y --no-install-recommends \
    libsndfile1 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY main.py .

RUN pip install --no-cache-dir \
    TTS \
    flask \
    torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cpu

EXPOSE 9001
CMD ["python", "main.py"]
EOF_COQUI_DOCKERFILE
echo_info "üì¶ Dockerfile verificado/creado para Coqui"

echo_info "Verificando arquivos base para o servi√ßo Whisper..."
WHISPER_PATH=./build/whisper
cat <<'EOF_WHISPER_MAIN' > "$WHISPER_PATH/main.py"
from faster_whisper import WhisperModel
from flask import Flask, request, jsonify
import tempfile
import os
import torch

app = Flask(__name__)

MODEL_SIZE = os.getenv("WHISPER_MODEL", "medium")
DEVICE = os.getenv("WHISPER_DEVICE", "cpu")
COMPUTE_TYPE = os.getenv("WHISPER_COMPUTE_TYPE", "int8")

if DEVICE == "cuda" and not torch.cuda.is_available():
    print("CUDA n√£o dispon√≠vel, for√ßando DEVICE='cpu' e COMPUTE_TYPE='int8'")
    DEVICE = "cpu"
    COMPUTE_TYPE = "int8"
elif DEVICE == "cuda":
     print(f"CUDA dispon√≠vel. Usando DEVICE='{DEVICE}' e COMPUTE_TYPE='{COMPUTE_TYPE}'")
else:
     print(f"Usando DEVICE='{DEVICE}' e COMPUTE_TYPE='{COMPUTE_TYPE}'")

try:
    model = WhisperModel(MODEL_SIZE, device=DEVICE, compute_type=COMPUTE_TYPE)
    print(f"Modelo Whisper '{MODEL_SIZE}' carregado com sucesso em '{DEVICE}' ({COMPUTE_TYPE}).")
except Exception as e:
    print(f"Erro ao carregar modelo Whisper '{MODEL_SIZE}': {e}")
    print("Verifique o nome do modelo, as depend√™ncias (Torch com ou sem GPU) e as configura√ß√µes de dispositivo/compute_type.")
    model = None

@app.route("/transcribe", methods=["POST"])
def transcribe():
    if model is None:
         return jsonify({"error": "Servi√ßo Whisper n√£o inicializado"}), 500

    if 'file' not in request.files:
        return jsonify({"error": "Nenhum arquivo fornecido"}), 400

    audio_file = request.files['file']
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        audio_file.save(tmp.name)
        temp_path = tmp.name

    text = ""
    try:
        language = os.getenv("WHISPER_LANGUAGE", None)
        print(f"Transcrevendo √°udio (idioma: {language})...")
        segments, info = model.transcribe(temp_path, language=language)
        print(f"Detec√ß√£o de idioma: {info.language} com probabilidade {info.language_probability:.2f}")
        text = " ".join([seg.text for seg in segments]).strip()
        print(f"Transcri√ß√£o conclu√≠da: \"{text[:100]}...\"")
        return jsonify({"transcription": text, "language": info.language, "language_probability": round(info.language_probability, 2)})
    except Exception as e:
        print(f"Erro durante a transcri√ß√£o: {e}")
        return jsonify({"error": f"Erro durante a transcri√ß√£o: {e}"}), 500
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

@app.route("/")
def status():
     if model is None:
        return jsonify({"status": "error", "message": "Servi√ßo Whisper n√£o inicializado."}), 500
     return jsonify({"status": "ok", "model": MODEL_SIZE, "device": DEVICE, "compute_type": COMPUTE_TYPE})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=9000)
EOF_WHISPER_MAIN
chmod +x "$WHISPER_PATH/main.py"
echo_info "üîß main.py verificado/criado para Whisper"

cat <<'EOF_WHISPER_DOCKERFILE' > "$WHISPER_PATH/Dockerfile"
FROM python:3.10-slim

RUN apt-get update && apt-get install -y --no-install-recommends \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app
COPY main.py .

RUN pip install --no-cache-dir \
    faster-whisper \
    flask \
    torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cpu

EXPOSE 9000
CMD ["python", "main.py"]
EOF_WHISPER_DOCKERFILE
echo_info "üì¶ Dockerfile verificado/criado para Whisper"

echo_info "Verificando arquivos base para o servi√ßo BLIP2..."
BLIP2_PATH=./build/blip2
cat <<'EOF_BLIP2_MAIN' > "$BLIP2_PATH/main.py"
from lavis.models import load_model_and_preprocess
from PIL import Image
from flask import Flask, request, jsonify
import torch
import os

app = Flask(__name__)

MODEL_TYPE = os.getenv("BLIP2_MODEL_TYPE", "blip2_t5")
MODEL_NAME = os.getenv("BLIP2_MODEL_NAME", "pretrain_flant5xl")
DEVICE = os.getenv("BLIP2_DEVICE", "cpu")

if DEVICE == "cuda" and not torch.cuda.is_available():
    print("CUDA n√£o dispon√≠vel, for√ßando DEVICE='cpu'")
    DEVICE = "cpu"
elif DEVICE == "cuda":
     print(f"CUDA dispon√≠vel. Usando DEVICE='{DEVICE}'")
else:
     print(f"Usando DEVICE='{DEVICE}'")

try:
    model, vis_processors, _ = load_model_and_preprocess(name=MODEL_TYPE, model_type=MODEL_NAME, is_eval=True, device=DEVICE)
    print(f"Modelo BLIP2 '{MODEL_TYPE}/{MODEL_NAME}' carregado com sucesso em '{DEVICE}'.")
except Exception as e:
    print(f"Erro ao carregar modelo BLIP2 '{MODEL_TYPE}/{MODEL_NAME}': {e}")
    print("Verifique o nome do modelo, as depend√™ncias (Torch com ou sem GPU) e as configura√ß√µes de dispositivo.")
    model = None
    vis_processors = None

@app.route("/describe", methods=["POST"])
def describe():
    if model is None or vis_processors is None:
        return jsonify({"error": "Servi√ßo BLIP2 n√£o inicializado"}), 500

    if 'file' not in request.files:
        return jsonify({"error": "Nenhum arquivo fornecido"}), 400

    try:
        image = Image.open(request.files['file'].stream).convert("RGB")
        image_tensor = vis_processors["eval"](image).unsqueeze(0).to(DEVICE)

        output = model.generate({"image": image_tensor})

        if output:
            description = output[0]
            print(f"Descri√ß√£o gerada: \"{description}\"")
            return jsonify({"description": description})
        else:
            return jsonify({"error": "Falha ao gerar descri√ß√£o."}), 500

    except Exception as e:
        print(f"Erro durante o processamento da imagem/descri√ß√£o: {e}")
        return jsonify({"error": f"Erro durante o processamento: {e}"}), 500

@app.route("/")
def status():
     if model is None:
        return jsonify({"status": "error", "message": "Servi√ßo BLIP2 n√£o inicializado."}), 500
     return jsonify({"status": "ok", "model_type": MODEL_TYPE, "model_name": MODEL_NAME, "device": DEVICE})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=9003)
EOF_BLIP2_MAIN
chmod +x "$BLIP2_PATH/main.py"
echo_info "üîß main.py verificado/criado para BLIP2"

cat <<'EOF_BLIP2_DOCKERFILE' > "$BLIP2_PATH/Dockerfile"
FROM python:3.10-slim

WORKDIR /app
COPY main.py .

RUN pip install --no-cache-dir \
    salesforce-lavis \
    flask \
    Pillow \
    transformers \
    torch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cpu

EXPOSE 9003
CMD ["python", "main.py"]
EOF_BLIP2_DOCKERFILE
echo_info "üì¶ Dockerfile verificado/criado para BLIP2"

echo_info "Verificando arquivos base para o servi√ßo SESANE..."
SESAME_PATH=./build/sesame
cat <<'EOF_SESAME_MAIN' > "$SESAME_PATH/main.py"
from flask import Flask, request, jsonify
import os
import requests
import json

app = Flask(__name__)

@app.route("/")
def hello_sesame():
    return "SESANE iniciado - agente cognitivo base aguardando comandos POST em /process."

@app.route("/process", methods=["POST"])
def process_command():
    data = request.json
    command = data.get("command", "")
    params = data.get("params", {})
    print(f"Comando recebido: {command}, Params: {params}")

    if not command:
        return jsonify({"status": "error", "message": "Nenhum comando fornecido"}), 400

    result = None
    error = None

    try:
        if command == "ask_llm":
            prompt = params.get("prompt", "Ol√°!")
            model_name = params.get("model", os.getenv("OLLAMA_DEFAULT_MODEL", "llama2"))

            ollama_host = os.getenv("OLLAMA_HOST", "llm-ollama")
            ollama_port = os.getenv("OLLAMA_PORT", "11434")
            ollama_url = f"http://{ollama_host}:{ollama_port}/api/generate"

            ollama_payload = {
                "model": model_name,
                "prompt": prompt,
                "stream": False
            }
            print(f"Chamando LLM: {ollama_url} com modelo '{model_name}' e prompt \"{prompt[:50]}...\"")
            response = requests.post(ollama_url, json=ollama_payload)
            response.raise_for_status()
            ollama_response = response.json()
            result = ollama_response.get("response", "Nenhuma resposta do LLM.")
            print("Resposta do LLM recebida.")

        elif command == "transcribe_audio":
            audio_url = params.get("audio_url")

            if not audio_url:
                return jsonify({"status": "error", "message": "URL de √°udio n√£o fornecida para transcri√ß√£o"}), 400

            whisper_host = os.getenv("WHISPER_HOST", "whisper")
            whisper_port = os.getenv("WHISPER_PORT", "9000")
            whisper_url = f"http://{whisper_host}:{whisper_port}/transcribe"

            try:
                 print(f"Baixando √°udio de: {audio_url}")
                 audio_response = requests.get(audio_url, stream=True)
                 audio_response.raise_for_status()
                 filename = 'audio.wav'
                 if 'content-disposition' in audio_response.headers:
                    import re
                    fname = re.findall('filename="(.+)"', audio_response.headers['content-disposition'])
                    if fname:
                        filename = fname[0]
                 elif audio_url.split('/')[-1]:
                     filename = audio_url.split('/')[-1]

                 files = {'file': (filename, audio_response.raw, audio_response.headers.get('Content-Type', 'application/octet-stream'))}

                 print(f"Enviando √°udio para transcri√ß√£o em: {whisper_url}")
                 transcribe_response = requests.post(whisper_url, files=files)
                 transcribe_response.raise_for_status()
                 transcription_data = transcribe_response.json()
                 result = transcription_data.get("transcription", "Falha na transcri√ß√£o.")
                 print(f"Transcri√ß√£o recebida: \"{result[:100]}...\"")

            except requests.exceptions.RequestException as e:
                 error = f"Erro ao processar √°udio ou chamar Whisper: {e}"
                 print(error)
                 return jsonify({"status": "error", "message": error}), 500

        elif command == "ping":
            result = "pong"

        else:
            error = f"Comando '{command}' n√£o reconhecido."
            print(error)
            return jsonify({"status": "error", "message": error}), 400

        return jsonify({"status": "success", "result": result})

    except requests.exceptions.RequestException as e:
        error = f"Erro ao chamar servi√ßo externo: {e}"
        print(error)
        return jsonify({"status": "error", "message": error}), 500
    except Exception as e:
        error = f"Erro interno no agente SESANE: {e}"
        print(error)
        return jsonify({"status": "error", "message": error}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8003)
EOF_SESAME_MAIN
chmod +x "$SESAME_PATH/main.py"
echo_info "üîß main.py verificado/criado para SESANE"

cat <<'EOF_SESAME_DOCKERFILE' > "$SESAME_PATH/Dockerfile"
FROM python:3.10-slim
WORKDIR /app
COPY main.py .
RUN pip install --no-cache-dir requests flask
EXPOSE 8003
CMD ["python", "main.py"]
EOF_SESAME_DOCKERFILE
echo_info "üì¶ Dockerfile verificado/criado para SESANE"

echo_info "Verificando arquivos base para o servi√ßo Jira..."
JIRA_PATH=./build/jira
cat <<'EOF_JIRA_MAIN' > "$JIRA_PATH/main.py"
echo "Este arquivo √© apenas um placeholder para o contexto de build do Jira."
EOF_JIRA_MAIN

cat <<'EOF_JIRA_DOCKERFILE' > "$JIRA_PATH/Dockerfile"
FROM atlassian/jira-software:latest
EOF_JIRA_DOCKERFILE
echo_info "üì¶ Dockerfile verificado/criado para Jira"

echo_info "Verificando reposit√≥rio do Stable Diffusion em $SD_CLONE_PATH..."

if [ ! -d "$SD_CLONE_PATH" ]; then
  echo_info "Diret√≥rio n√£o encontrado. Clonando reposit√≥rio de $SD_REPO_URL em $SD_CLONE_PATH..."
  git clone --depth=1 "$SD_REPO_URL" "$SD_CLONE_PATH"
  if [ $? -ne 0 ]; then
    echo_error "‚ùå Falha ao clonar reposit√≥rio do Stable Diffusion de $SD_REPO_URL."
    echo_error "Verifique sua conex√£o com a internet, permiss√µes e se o URL do reposit√≥rio est√° correto."
  else
    echo_done "üì¶ Reposit√≥rio do Stable Diffusion clonado com sucesso."
  fi
else
  if [ -d "$SD_CLONE_PATH/.git" ]; then
    echo_done "Reposit√≥rio do Stable Diffusion j√° clonado em $SD_CLONE_PATH."
  else
    echo_error "‚ùå Diret√≥rio $SD_CLONE_PATH existe, mas N√ÉO √© um reposit√≥rio Git v√°lido."
    echo_error "N√£o √© seguro clonar ou prosseguir. Por favor, remova a pasta manualmente e execute o script novamente."
    read -n 1 -s -r -p "${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"
    exit 1
  fi
fi

if [ -f "$SD_CLONE_PATH/Dockerfile" ]; then
  echo_info "Removendo Dockerfile tempor√°rio na raiz do reposit√≥rio clonado ($SD_CLONE_PATH/Dockerfile)."
  rm "$SD_CLONE_PATH/Dockerfile" || echo_warn "Falha ao remover Dockerfile tempor√°rio. Prosseguindo..."
fi
echo_done "Verifica√ß√£o de arquivos base para Stable Diffusion completa."

echo_info "Verificando se Dockerfiles para build existem..."
REQUIRED_DOCKERFILES=(
  "./build/venom/Dockerfile"
  "./build/sesame/Dockerfile"
  "./build/whisper/Dockerfile"
  "./build/coqui/Dockerfile"
  "./build/jira/Dockerfile"
  "./build/blip2/Dockerfile"
)

for df in "${REQUIRED_DOCKERFILES[@]}"; do
  if [ ! -f "$df" ]; then
    echo_error "‚ùå Dockerfile ausente ap√≥s a prepara√ß√£o do script: $df"
    echo_error "Algo deu errado na cria√ß√£o de arquivos. Verifique os logs acima."
    read -n 1 -s -r -p "${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"
    exit 1
  fi
done
echo_done "Verifica√ß√£o de Dockerfiles para build completa."

echo_info "Validando a sintaxe do arquivo Docker Compose ($DOCKER_COMPOSE_FILE)..."
VALIDATION_OUTPUT=$(docker compose -f "$DOCKER_COMPOSE_FILE" config --quiet 2>&1)
if [ $? -ne 0 ]; then
  echo_error "‚ùå Falha na valida√ß√£o da sintaxe do arquivo Docker Compose ($DOCKER_COMPOSE_FILE)."
  echo_error "Mensagem de erro do Docker Compose:"
  echo -e "${RED}$VALIDATION_OUTPUT${RESET}"
  echo_error "Verifique a sintaxe e a indenta√ß√£o YAML neste arquivo."
  echo_error "Use um validador online como https://yamlvalidator.com/ para ajudar."
  read -n 1 -s -r -p "${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"
  exit 1
fi
echo_done "Valida√ß√£o do arquivo Docker Compose bem-sucedida."

if [ -n "$BUILD_FLAG" ]; then
  echo_info "Construindo imagens Docker com Docker Compose..."
  docker compose -f "$DOCKER_COMPOSE_FILE" build $ONLY
  BUILD_EXIT_CODE=$?
  if [ $BUILD_EXIT_CODE -ne 0 ]; then
    echo_error "‚ùå Falha ao construir imagens Docker (c√≥digo de sa√≠da $BUILD_EXIT_CODE)."
    echo_error "Verifique os logs de build acima para detalhes do erro."
    read -n 1 -s -r -p "${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"
    exit $BUILD_EXIT_CODE
  fi
  echo_done "Constru√ß√£o de imagens Docker completa."
else
    echo_info "Flag --build n√£o ativo. Puxando imagens e usando locais existentes..."
    docker compose -f "$DOCKER_COMPOSE_FILE" pull $ONLY || echo_warn "Falha ao puxar algumas imagens. O Docker Compose tentar√° usar imagens locais ou constru√≠das."
fi

echo_info "Iniciando containers com Docker Compose..."
docker compose -f "$DOCKER_COMPOSE_FILE" up -d --wait --remove-orphans $BUILD_FLAG $ONLY
UP_EXIT_CODE=$?

if [ $UP_EXIT_CODE -ne 0 ]; then
  echo_error "‚ùå Falha ao iniciar containers (c√≥digo de sa√≠da $UP_EXIT_CODE)."
  echo_error "Verifique os logs de runtime dos containers para diagnosticar o problema."
  echo_info "Exibindo logs recentes dos containers:"
  docker compose -f "$DOCKER_COMPOSE_FILE" logs --tail 50
  read -n 1 -s -r -p "${CYAN}üîÅ Pressione qualquer tecla para sair...${RESET}"
  exit $UP_EXIT_CODE
else
  echo_done "Containers iniciados com sucesso!"
fi

echo_info "Status dos containers Safira:"
docker compose -f "$DOCKER_COMPOSE_FILE" ps

echo -e "\n${BOLD}üöÄ Ambiente Safira iniciado! Endpoints dispon√≠veis:${RESET}"
echo -e "${BOLD}üîß Orquestrador (n8n):${RESET}        http://localhost:5678"
echo -e "${BOLD}üì≤ WhatsApp (Venom):${RESET}          http://localhost:3000"
echo -e "${BOLD}üß† LLM Ollama:${RESET}                http://localhost:11434"
echo -e "${BOLD}üéôÔ∏è STT Whisper:${RESET}              http://localhost:9000"
echo -e "${BOLD}üó£Ô∏è TTS Coqui:${RESET}                 http://localhost:9001"
echo -e "${BOLD}üìä Grafana:${RESET}                   http://localhost:3001"
echo -e "${BOLD}üõ†Ô∏è Jenkins:${RESET}                  http://localhost:8083"
echo -e "${BOLD}üßæ Jira:${RESET}                     http://localhost:8082"
echo -e "${BOLD}üß† SESANE:${RESET}                   http://localhost:8003"
echo -e "${BOLD}üé® Stable Diffusion:${RESET}         http://localhost:7860"
echo -e "${BOLD}üì¶ MinIO:${RESET}                    http://localhost:9002"
echo -e "${BOLD}üîÑ Traefik:${RESET}                  http://localhost:8080"
echo -e "${BOLD}üß± NGINX:${RESET}                   http://localhost:8081"
echo -e "${BOLD}üíæ PostgreSQL:${RESET}               localhost:5432"
echo -e "${BOLD}üöÑ Redis:${RESET}                    localhost:6379"
echo -e "${BOLD}üìà Prometheus:${RESET}               http://localhost:9090"

echo "\n${GREEN}‚úÖ Script run.sh conclu√≠do.${RESET}"